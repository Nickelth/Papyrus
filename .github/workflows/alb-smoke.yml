name: alb-smoke
on: workflow_dispatch
permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  VPC_ID: ${{ secrets.VPC_ID }}
  PUBLIC_SUBNET_IDS_JSON: ${{ secrets.PUBLIC_SUBNET_IDS }}
  ECS_CLUSTER: ${{ vars.ECS_CLUSTER }}
  ECS_SERVICE: ${{ vars.ECS_SERVICE }}
  CONTAINER_PORT: ${{ vars.CONTAINER_PORT }}

jobs:
  smoke:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Preflight App Health Check
        run: |
          python - <<'PY'
          from papyrus import create_app
          app = create_app()
          routes = sorted([r.rule for r in app.url_map.iter_rules()])
          print("ROUTES:", routes)
          assert "/dbcheck" in routes, "dbcheck missing"
          assert "/healthz" in routes, "healthz missing"
          PY
          
      - name: Preflight and connection information drift detection
        run: | 
          SEC_JSON=$(aws secretsmanager get-secret-value \
            --secret-id papyrus/prd/db \
            --query SecretString \
            --output text)

          EP=$(aws rds describe-db-instances \
            --db-instance-identifier papyrus-pg16-dev \
            --query 'DBInstances[0].Endpoint.Address' \
            --output text)

          PORT=$(aws rds describe-db-instances \
            --db-instance-identifier papyrus-pg16-dev \
            --query 'DBInstances[0].Endpoint.Port' \
            --output text)

          SEC_HOST=$(echo "$SEC_JSON" | jq -r .host)
          SEC_PORT=$(echo "$SEC_JSON" | jq -r .port)

          test "$SEC_HOST" = "$EP"   || { echo "FATAL: RDS endpoint drift"; exit 1; }
          test "$SEC_PORT" = "$PORT" || { echo "FATAL: RDS port drift"; exit 1; }

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.5
          terraform_wrapper: false

      - name: AWS creds
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_IAM_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Write tfvars (runtime only)
        working-directory: infra/20-alb
        run: |
          cat > dev.auto.tfvars <<'TFV'
          vpc_id            = ${{ env.VPC_ID }}
          public_subnet_ids = ${{ env.PUBLIC_SUBNET_IDS_JSON }}
          container_port    = 5000
          allow_cidrs       = ["0.0.0.0/0"]
          ecs_tasks_sg_id   = "${{ secrets.ECS_TASK_SG_ID }}"
          TFV

      - name: Terraform apply (ALB/TG only)
        working-directory: infra/20-alb
        env:
          TF_IN_AUTOMATION: "1"
        run: |
          terraform init -input=false -upgrade=false
          terraform validate
          terraform apply -auto-approve -var-file=dev.auto.tfvars

      - name: Export outputs
        id: outs
        working-directory: infra/20-alb
        run: |
          echo "alb_dns=$(terraform output -raw alb_dns_name)" >> $GITHUB_OUTPUT
          echo "tg_arn=$(terraform output -raw tg_arn)" >> $GITHUB_OUTPUT

      - name: Save outputs artifact
        uses: actions/upload-artifact@v4
        with:
          name: alb-outputs
          path: |
            infra/20-alb/terraform.tfstate

      - name: Resolve ECS task IP
        id: ecsinfo
        run: |
          set -euo pipefail

          TASK_ARN=$(aws ecs list-tasks \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --service-name "${{ env.ECS_SERVICE }}" \
            --desired-status RUNNING \
            --query 'taskArns[0]' \
            --output text)

          echo "TASK_ARN=$TASK_ARN"

          ENI_ID=$(aws ecs describe-tasks \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].attachments[0].details[?name==`networkInterfaceId`].value' \
            --output text)

          echo "ENI_ID=$ENI_ID"

          TASK_IP=$(aws ec2 describe-network-interfaces \
            --network-interface-ids "$ENI_ID" \
            --query 'NetworkInterfaces[0].PrivateIpAddress' \
            --output text)

          echo "TASK_IP=$TASK_IP"

          {
            echo "task_arn=$TASK_ARN"
            echo "eni_id=$ENI_ID"
            echo "task_ip=$TASK_IP"
          } >> $GITHUB_OUTPUT

      - name: Register target
        run: |
          set -euo pipefail
          TG_ARN="${{ steps.outs.outputs.tg_arn }}"
          TASK_IP="${{ steps.ecsinfo.outputs.task_ip }}"
          PORT="${{ env.CONTAINER_PORT }}"

          echo "Registering $TASK_IP:$PORT to $TG_ARN"

          aws elbv2 register-targets \
            --target-group-arn "$TG_ARN" \
            --targets "Id=$TASK_IP,Port=$PORT"

          aws elbv2 wait target-in-service \
            --target-group-arn "$TG_ARN" \
            --targets "Id=$TASK_IP,Port=$PORT"

      - name: Smoke hit /healthz and /dbcheck
        run: |
          set -euo pipefail

          EVID_DIR="evidence"
          mkdir -p "$EVID_DIR"

          DNS="${{ steps.outs.outputs.alb_dns }}"
          TS=$(date +%Y%m%d_%H%M%S)

          HEALTHZ_LOG="$EVID_DIR/${TS}_healthz.log"
          DBCHECK_LOG="$EVID_DIR/${TS}_dbcheck.log"

          echo "[INFO] curl /healthz" | tee "$HEALTHZ_LOG" || true
          curl -si "http://$DNS/healthz" \
            | tee -a "$HEALTHZ_LOG" \
            || true

          echo "[INFO] curl /dbcheck" | tee "$DBCHECK_LOG" || true
          curl -si "http://$DNS/dbcheck" \
            | tee -a "$DBCHECK_LOG" \
            || true

      - name: Upload smoke evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-${{ github.run_id }}
          path: |
            evidence/
            infra/20-alb/terraform.tfstate

      - name: Save outputs artifact
        uses: actions/upload-artifact@v4
        with:
          name: alb-smoke-artifacts
          path: |
            infra/20-alb/terraform.tfstate
            evidence/*.log

      - name: Terraform destroy (always)
        if: always()
        working-directory: infra/20-alb
        run: terraform destroy -auto-approve -var-file=dev.auto.tfvars